{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# T07 : Machine Learning & Évaluation\n",
                "\n",
                "## 1. Contexte et Objectifs\n",
                "\n",
                "Cette étape consiste à entraîner des modèles de Machine Learning supervisés pour prédire la direction future du marché GBP/USD à l'horizon M15. Nous respectons strictement le découpage temporel imposé :\n",
                "- **Train (2022)** : Apprentissage du modèle.\n",
                "- **Validation (2023)** : Sélection et hyper-paramétrage (si applicable).\n",
                "- **Test (2024)** : Évaluation finale (Sanctuarisée).\n",
                "\n",
                "**Objectif de prédiction** : Classifieur binaire `y`.\n",
                "- `1` : Hausse (Close[t+1] > Close[t])\n",
                "- `0` : Baisse ou Stagnation (Close[t+1] <= Close[t])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import TimeSeriesSplit\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
                "import os\n",
                "\n",
                "# Configuration Graphique\n",
                "sns.set_theme(style=\"whitegrid\")\n",
                "plt.rcParams.update({\n",
                "    \"figure.facecolor\": \"#FAF0E6\",\n",
                "    \"axes.facecolor\": \"#F5F5DC\",\n",
                "    \"grid.color\": \"#E0D0C0\",\n",
                "    \"text.color\": \"#5D4037\",\n",
                "    \"axes.prop_cycle\": plt.cycler(color=['#8D6E63', '#A1887F', '#D7CCC8'])\n",
                "})\n",
                "\n",
                "DATA_DIR = \"data/features\"\n",
                "MODELS_DIR = \"models/v1\"\n",
                "os.makedirs(MODELS_DIR, exist_ok=True)\n",
                "\n",
                "FILES = {\n",
                "    \"TRAIN\": \"GBPUSD_M15_2022_features.csv\",\n",
                "    \"VAL\": \"GBPUSD_M15_2023_features.csv\",\n",
                "    \"TEST\": \"GBPUSD_M15_2024_features.csv\"\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Préparation des Données (Data Loading & Preprocessing)\n",
                "\n",
                "Nous devons :\n",
                "1. Charger les features.\n",
                "2. Créer la cible (`target`) : Le signe du rendement futur.\n",
                "3. Séparer X (features) et y (target).\n",
                "4. Normaliser les données en apprenant les paramètres (`mean`, `std`) **uniquement sur le Train**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_and_prep(filename):\n",
                "    path = os.path.join(DATA_DIR, filename)\n",
                "    if not os.path.exists(path):\n",
                "        raise FileNotFoundError(f\"Fichier introuvable: {path}\")\n",
                "    \n",
                "    df = pd.read_csv(path, parse_dates=['timestamp'], index_col='timestamp')\n",
                "    \n",
                "    # Création de la target (futur immédiat)\n",
                "    # Shift(-1) permet de regarder la bougie SUIVANTE\n",
                "    # Attention : la dernière ligne aura un NaN et devra être supprimée\n",
                "    df['target_return'] = df['close_15m'].shift(-1) - df['close_15m']\n",
                "    df['target'] = (df['target_return'] > 0).astype(int)\n",
                "    \n",
                "    # Suppression de la dernière ligne (pas de futur connu)\n",
                "    df.dropna(inplace=True)\n",
                "    \n",
                "    return df\n",
                "\n",
                "# Chargement\n",
                "df_train = load_and_prep(FILES[\"TRAIN\"])\n",
                "df_val = load_and_prep(FILES[\"VAL\"])\n",
                "df_test = load_and_prep(FILES[\"TEST\"])\n",
                "\n",
                "print(f\"Train size : {df_train.shape}\")\n",
                "print(f\"Val size   : {df_val.shape}\")\n",
                "print(f\"Test size  : {df_test.shape}\")\n",
                "\n",
                "# Sélection des features (tout sauf les colonnes 'target' et les prix bruts si nécessaire)\n",
                "# On exclut les colonnes 'futur' ou 'target'\n",
                "drop_cols = ['target', 'target_return', 'open_15m', 'high_15m', 'low_15m', 'close_15m', 'volume_15m', 'tick_count']\n",
                "# On garde les indicateurs calculés\n",
                "features_cols = [c for c in df_train.columns if c not in drop_cols]\n",
                "\n",
                "X_train = df_train[features_cols]\n",
                "y_train = df_train['target']\n",
                "\n",
                "X_val = df_val[features_cols]\n",
                "y_val = df_val['target']\n",
                "\n",
                "X_test = df_test[features_cols]\n",
                "y_test = df_test['target']\n",
                "\n",
                "# Normalisation (StandardScaler)\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "# Important : On utilise le scaler fitté sur le TRAIN pour transformer VAL et TEST\n",
                "X_val_scaled = scaler.transform(X_val)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "\n",
                "print(f\"\\nFeatures ({len(features_cols)}) : {features_cols}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Modélisation : Baseline & Random Forest\n",
                "\n",
                "Nous commençons par une régression logistique simple comme 'baseline', puis un Random Forest."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "models = {\n",
                "    \"Logistic Regression\": LogisticRegression(random_state=42, class_weight='balanced'),\n",
                "    \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42, class_weight='balanced') # Max depth limité pour éviter overfitting\n",
                "}\n",
                "\n",
                "results = {}\n",
                "\n",
                "for name, model in models.items():\n",
                "    print(f\"\\n--- Entraînement {name} ---\")\n",
                "    model.fit(X_train_scaled, y_train)\n",
                "    \n",
                "    # Prédictions\n",
                "    train_pred = model.predict(X_train_scaled)\n",
                "    val_pred = model.predict(X_val_scaled)\n",
                "    \n",
                "    # Stockage des modèles et stats\n",
                "    acc_train = accuracy_score(y_train, train_pred)\n",
                "    acc_val = accuracy_score(y_val, val_pred)\n",
                "    \n",
                "    print(f\"Accuracy Train : {acc_train:.4f}\")\n",
                "    print(f\"Accuracy Val   : {acc_val:.4f}\")\n",
                "    print(\"Rapport de classification (Val) :\")\n",
                "    print(classification_report(y_val, val_pred))\n",
                "    \n",
                "    results[name] = model"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Évaluation Financière (Backtest Vectorisé)\n",
                "\n",
                "L'accuracy ne suffit pas. Nous devons vérifier si le modèle génère du profit.\n",
                "Simulation simple : \n",
                "- Si Pred = 1 (Hausse) -> Achat (Long)\n",
                "- Si Pred = 0 (Baisse) -> Vente (Short) ou Cash (Flat)? \n",
                "Pour simplifier ici, supposons une stratégie 'Long Only' filtrée (on n'achète que si Pred=1) ou 'Long/Short'.\n",
                "Prenons le cas **Long/Short** pour maximiser l'impact de la prédiction : \n",
                "- Signal = 1 -> Return du marché\n",
                "- Signal = 0 -> - Return du marché (Short)\n",
                "\n",
                "*Note : Sans coûts de transaction pour l'instant (brut).*"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def backtest_model(model, X, df_original, title=\"\"):\n",
                "    preds = model.predict(X)\n",
                "    \n",
                "    # Stratégie : 1 -> Long (+return), 0 -> Short (-return)\n",
                "    # Mapping 0 -> -1\n",
                "    signals = np.where(preds == 1, 1, -1)\n",
                "    \n",
                "    # Calcul du PnL cumulé\n",
                "    # On multiplie le signal par le retour futur 'target_return'\n",
                "    strategy_returns = signals * df_original['target_return']\n",
                "    cumulative_returns = strategy_returns.cumsum()\n",
                "    \n",
                "    # Baseline Buy & Hold\n",
                "    market_returns = df_original['target_return'].cumsum()\n",
                "    \n",
                "    # Plot\n",
                "    plt.figure(figsize=(12, 6))\n",
                "    plt.plot(df_original.index, cumulative_returns, label='Modèle Strategy', color='#8D6E63')\n",
                "    plt.plot(df_original.index, market_returns, label='Buy & Hold', color='gray', alpha=0.5, linestyle='--')\n",
                "    plt.title(f\"PnL Cumulé - {title}\", fontweight='bold')\n",
                "    plt.ylabel(\"Pips / Points cumulés\")\n",
                "    plt.legend()\n",
                "    plt.show()\n",
                "    \n",
                "    return cumulative_returns.iloc[-1]\n",
                "\n",
                "# Évaluation sur le Test Set (2024)\n",
                "print(\"\\n=== ÉVALUATION FINALE SUR TEST (2024) ===\")\n",
                "best_model = results['Random Forest'] # On choisit le RF par défaut\n",
                "\n",
                "final_pnl = backtest_model(best_model, X_test_scaled, df_test, title=\"Test 2024 (Random Forest)\")\n",
                "print(f\"Profit Final (Points) sur 2024 : {final_pnl:.5f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Analyse de l'Importance des Features\n",
                "\n",
                "Quelles variables ont le plus influencé le modèle de Random Forest ?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "importances = best_model.feature_importances_\n",
                "indices = np.argsort(importances)[::-1]\n",
                "\n",
                "plt.figure(figsize=(12, 6))\n",
                "plt.title(\"Importance des Features (Random Forest)\")\n",
                "plt.bar(range(X_train.shape[1]), importances[indices], align=\"center\", color='#A1887F')\n",
                "plt.xticks(range(X_train.shape[1]), [features_cols[i] for i in indices], rotation=45, ha='right')\n",
                "plt.xlim([-1, X_train.shape[1]])\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Conclusion T07\n",
                "\n",
                "Ce notebook a permis d'entraîner et valider une première approche ML.\n",
                "\n",
                "**Points Clés :**\n",
                "- Le split temporel a été respecté.\n",
                "- La normalisation est ancrée sur le Train set.\n",
                "- Une évaluation financière brute a été réalisée sur 2024.\n",
                "\n",
                "**Limitations :**\n",
                "- Le modèle reste basique (Random Forest standard).\n",
                "- Les coûts de transaction (spread) ne sont pas inclus dans le backtest, ce qui rend les résultats probablement optimistes.\n",
                "- L'horizon de prédiction est très court (M15 suivant).\n",
                "\n",
                "**Pour la suite (T08 - RL) :** Le Reinforcement Learning pourra potentiellement mieux gérer la séquence de décision (Garder vs Vendre) et intégrer les coûts de manière native dans la fonction de récompense."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}