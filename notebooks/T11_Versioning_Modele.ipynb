{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# T11 : Versioning de Mod√®le et Registry (MLOps)\n",
                "\n",
                "## Objectif\n",
                "Mettre en place un syst√®me de **Model Registry** l√©ger mais robuste pour :\n",
                "1.  G√©rer les versions successives des mod√®les (v1, v2...).\n",
                "2.  Tracer les hyperparam√®tres et les m√©triques de performance.\n",
                "3.  Comparer automatiquement les versions (Rapport d'√©volution).\n",
                "4.  Permettre le chargement facile de la \"derni√®re meilleure version\" pour la production.\n",
                "\n",
                "Ce syst√®me remplace des outils lourds comme MLflow dans cet environnement contraint, en utilisant une structure de fichiers JSON + Pickle standardis√©e."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import json\n",
                "import pickle\n",
                "import os\n",
                "import shutil\n",
                "from datetime import datetime\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
                "\n",
                "# Configuration\n",
                "MODELS_DIR = '../models'\n",
                "DATA_DIR = '../data/features/'\n",
                "\n",
                "# Cr√©ation du dossier models s'il n'existe pas\n",
                "os.makedirs(MODELS_DIR, exist_ok=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Classe `ModelRegistry`\n",
                "Le c≈ìur du syst√®me de versioning."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ModelRegistry:\n",
                "    def __init__(self, registry_path=MODELS_DIR):\n",
                "        self.registry_path = registry_path\n",
                "        self.registry_file = os.path.join(registry_path, 'registry.json')\n",
                "        self._load_registry()\n",
                "\n",
                "    def _load_registry(self):\n",
                "        if os.path.exists(self.registry_file):\n",
                "            with open(self.registry_file, 'r') as f:\n",
                "                self.registry = json.load(f)\n",
                "        else:\n",
                "            self.registry = {'models': {}}\n",
                "\n",
                "    def _save_registry(self):\n",
                "        with open(self.registry_file, 'w') as f:\n",
                "            json.dump(self.registry, f, indent=4)\n",
                "\n",
                "    def register_model(self, model, name, params, metrics, author=\"User\"):\n",
                "        \"\"\"Enregistre une nouvelle version du mod√®le.\"\"\"\n",
                "        if name not in self.registry['models']:\n",
                "            self.registry['models'][name] = []\n",
                "        \n",
                "        version_id = len(self.registry['models'][name]) + 1\n",
                "        version_tag = f\"v{version_id}\"\n",
                "        timestamp = datetime.now().isoformat()\n",
                "        \n",
                "        # Cr√©ation du dossier de version\n",
                "        model_dir = os.path.join(self.registry_path, name, version_tag)\n",
                "        os.makedirs(model_dir, exist_ok=True)\n",
                "        \n",
                "        # Sauvegarde du mod√®le (Pickle)\n",
                "        model_path = os.path.join(model_dir, 'model.pkl')\n",
                "        with open(model_path, 'wb') as f:\n",
                "            pickle.dump(model, f)\n",
                "            \n",
                "        # M√©tadonn√©es\n",
                "        metadata = {\n",
                "            'version': version_tag,\n",
                "            'timestamp': timestamp,\n",
                "            'author': author,\n",
                "            'params': params,\n",
                "            'metrics': metrics,\n",
                "            'path': model_path\n",
                "        }\n",
                "        \n",
                "        # Sauvegarde locale des m√©tadonn√©es\n",
                "        with open(os.path.join(model_dir, 'meta.json'), 'w') as f:\n",
                "            json.dump(metadata, f, indent=4)\n",
                "            \n",
                "        # Mise √† jour du registre central\n",
                "        self.registry['models'][name].append(metadata)\n",
                "        self._save_registry()\n",
                "        \n",
                "        print(f\"‚úÖ Mod√®le {name} version {version_tag} enregistr√© avec succ√®s.\")\n",
                "        return version_tag\n",
                "\n",
                "    def get_history(self, name):\n",
                "        \"\"\"Retourne l'historique des versions sous forme de DataFrame.\"\"\"\n",
                "        if name not in self.registry['models']:\n",
                "            return pd.DataFrame()\n",
                "        \n",
                "        history = []\n",
                "        for entry in self.registry['models'][name]:\n",
                "            # Aplatir le dictionnaire pour le DataFrame\n",
                "            row = {\n",
                "                'version': entry['version'],\n",
                "                'date': entry['timestamp'][:10],\n",
                "                **entry['metrics'], # Metriques en colonnes\n",
                "                **{f\"param_{k}\": v for k, v in entry['params'].items()} # Params pr√©fix√©s\n",
                "            }\n",
                "            history.append(row)\n",
                "            \n",
                "        return pd.DataFrame(history)\n",
                "\n",
                "    def load_model(self, name, version='latest'):\n",
                "        \"\"\"Charge un mod√®le sp√©cifique ou le dernier.\"\"\"\n",
                "        if name not in self.registry['models']:\n",
                "            raise ValueError(f\"Mod√®le {name} inconnu.\")\n",
                "            \n",
                "        if version == 'latest':\n",
                "            meta = self.registry['models'][name][-1]\n",
                "        else:\n",
                "            meta = next((m for m in self.registry['models'][name] if m['version'] == version), None)\n",
                "            if meta is None:\n",
                "                raise ValueError(f\"Version {version} non trouv√©e pour {name}.\")\n",
                "        \n",
                "        with open(meta['path'], 'rb') as f:\n",
                "            model = pickle.load(f)\n",
                "            \n",
                "        print(f\"üìÇ Mod√®le {name} ({meta['version']}) charg√©.\")\n",
                "        return model, meta\n",
                "\n",
                "    def compare_versions(self, name, v_a, v_b):\n",
                "        \"\"\"G√©n√®re un rapport de comparaison entre deux versions.\"\"\"\n",
                "        df = self.get_history(name)\n",
                "        row_a = df[df['version'] == v_a].iloc[0]\n",
                "        row_b = df[df['version'] == v_b].iloc[0]\n",
                "        \n",
                "        print(f\"--- Comparaison : {v_a} vs {v_b} ---n\")\n",
                "        \n",
                "        # Comparaison M√©triques\n",
                "        metrics_cols = [c for c in df.columns if c not in ['version', 'date'] and not c.startswith('param_')]\n",
                "        diffs = []\n",
                "        for m in metrics_cols:\n",
                "            val_a = row_a[m]\n",
                "            val_b = row_b[m]\n",
                "            diff = val_b - val_a\n",
                "            pct = (diff / val_a) * 100 if val_a != 0 else 0\n",
                "            icon = \"üü¢\" if diff > 0 else \"üî¥\" if diff < 0 else \"‚ö™\"\n",
                "            diffs.append({'M√©trique': m, v_a: val_a, v_b: val_b, 'Diff': diff, 'Diff %': f\"{pct:+.2f}%\", 'Status': icon})\n",
                "            \n",
                "        print(\"\\nM√©triques :\")\n",
                "        display(pd.DataFrame(diffs))\n",
                "        \n",
                "        # Comparaison Param√®tres\n",
                "        params_cols = [c for c in df.columns if c.startswith('param_')]\n",
                "        param_changes = []\n",
                "        for p in params_cols:\n",
                "            if row_a[p] != row_b[p]:\n",
                "                param_changes.append({'Param√®tre': p.replace('param_', ''), v_a: row_a[p], v_b: row_b[p]})\n",
                "        \n",
                "        if param_changes:\n",
                "            print(\"\\nChangements de Param√®tres :\")\n",
                "            display(pd.DataFrame(param_changes))\n",
                "        else:\n",
                "            print(\"\\nAucun changement de param√®tre d√©tect√©.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Chargement des Donn√©es"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_data(data_dir):\n",
                "    files = ['GBPUSD_M15_2022_features.csv', 'GBPUSD_M15_2024_features.csv'] # On charge Train et Test\n",
                "    dfs = []\n",
                "    for f in files:\n",
                "        path = os.path.join(data_dir, f)\n",
                "        if os.path.exists(path):\n",
                "            df_year = pd.read_csv(path, parse_dates=['timestamp'], index_col='timestamp')\n",
                "            dfs.append(df_year)\n",
                "            \n",
                "    if not dfs:\n",
                "        raise FileNotFoundError(\"Donn√©es non trouv√©es.\")\n",
                "        \n",
                "    df = pd.concat(dfs)\n",
                "    df.sort_index(inplace=True)\n",
                "    \n",
                "    # Target\n",
                "    df['target_return'] = df['close_15m'].shift(-1) - df['close_15m']\n",
                "    df['target'] = (df['target_return'] > 0).astype(int)\n",
                "    df.dropna(inplace=True)\n",
                "    return df\n",
                "\n",
                "df = load_data(DATA_DIR)\n",
                "train_data = df.loc['2022']\n",
                "test_data = df.loc['2024']\n",
                "\n",
                "features = ['rsi_14', 'ema_20', 'ema_50', 'atr_14', 'adx_14']\n",
                "X_train, y_train = train_data[features], train_data['target']\n",
                "X_test, y_test = test_data[features], test_data['target']\n",
                "\n",
                "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Entra√Ænement et Versioning\n",
                "\n",
                "### Version 1 : Baseline (Random Forest Default)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "registry = ModelRegistry()\n",
                "MODEL_NAME = \"rf_direction_classifier\"\n",
                "\n",
                "# --- V1 ---\n",
                "params_v1 = {\n",
                "    'n_estimators': 50,\n",
                "    'max_depth': 3,\n",
                "    'random_state': 42\n",
                "}\n",
                "\n",
                "print(\"Training V1...\")\n",
                "model_v1 = RandomForestClassifier(**params_v1)\n",
                "model_v1.fit(X_train, y_train)\n",
                "\n",
                "# Eval V1\n",
                "y_pred_v1 = model_v1.predict(X_test)\n",
                "metrics_v1 = {\n",
                "    'accuracy': accuracy_score(y_test, y_pred_v1),\n",
                "    'f1_score': f1_score(y_test, y_pred_v1)\n",
                "}\n",
                "\n",
                "# Enregistrement V1\n",
                "registry.register_model(model_v1, MODEL_NAME, params_v1, metrics_v1, author=\"JCLoirat\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Version 2 : Optimis√© (Plus d'arbres, plus profond)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- V2 ---\n",
                "params_v2 = {\n",
                "    'n_estimators': 200,  # Augment√©\n",
                "    'max_depth': 10,      # Augment√©\n",
                "    'min_samples_leaf': 5, # Ajout√© pour √©viter l'overfit\n",
                "    'random_state': 42\n",
                "}\n",
                "\n",
                "print(\"Training V2...\")\n",
                "model_v2 = RandomForestClassifier(**params_v2)\n",
                "model_v2.fit(X_train, y_train)\n",
                "\n",
                "# Eval V2\n",
                "y_pred_v2 = model_v2.predict(X_test)\n",
                "metrics_v2 = {\n",
                "    'accuracy': accuracy_score(y_test, y_pred_v2),\n",
                "    'f1_score': f1_score(y_test, y_pred_v2)\n",
                "}\n",
                "\n",
                "# Enregistrement V2\n",
                "registry.register_model(model_v2, MODEL_NAME, params_v2, metrics_v2, author=\"JCLoirat\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Analyse et Rapport d'√âvolution\n",
                "Visualisation de l'historique et des changements."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Afficher tout l'historique\n",
                "print(\"üìú Historique du Mod√®le :\")\n",
                "history = registry.get_history(MODEL_NAME)\n",
                "display(history)\n",
                "\n",
                "# Comparer V1 et V2\n",
                "registry.compare_versions(MODEL_NAME, 'v1', 'v2')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. D√©mo : Chargement en Production\n",
                "Simulation de l'utilisation du registry par une API ou un syst√®me de trading."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"üöÄ Simulation Production Startup...\")\n",
                "\n",
                "# Chargement automatique de la derni√®re version\n",
                "prod_model, prod_meta = registry.load_model(MODEL_NAME, version='latest')\n",
                "\n",
                "print(f\"Pr√™t √† utiliser le mod√®le v{prod_meta['version']} cr√©√© le {prod_meta['timestamp']}\")\n",
                "print(f\"Performance attendue (Accuracy) : {prod_meta['metrics']['accuracy']:.2%}\")\n",
                "\n",
                "# Test inf√©rence rapide\n",
                "sample = X_test.iloc[0:1]\n",
                "prediction = prod_model.predict(sample)\n",
                "print(f\"Prediction pour l'√©chantillon : {'HAUSSE' if prediction[0]==1 else 'BAISSE'}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}