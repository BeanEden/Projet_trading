{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# T09 : Évaluation Comparative Robuste (ML vs Règles vs RL)\n",
                "\n",
                "## Objectif\n",
                "Ce notebook finale vise à comparer les performances de trois approches de trading sur le jeu de données de test (2024), qui n'a jamais été vu par les modèles :\n",
                "\n",
                "1.  **Approche Règles (Rule-Based)** : Stratégie classique EMA + RSI.\n",
                "2.  **Approche Machine Learning (ML)** : Random Forest (Classification de la direction).\n",
                "3.  **Approche Reinforcement Learning (RL)** : Simulation de l'environnement (Agent PPO basique/aléatoire en l'absence de librairie RL avancée).\n",
                "\n",
                "## Méthodologie\n",
                "- **Données** : GBP/USD M15 (2022-2024).\n",
                "- **Train** : 2022 | **Val** : 2023 | **Test** : 2024 (Strictement séparés).\n",
                "- **Coûts** : Spread + Commission simulés (0.0002 ou 2 pips).\n",
                "- **Métriques** : Sharpe Ratio, Max Drawdown, Profit Factor, Win Rate.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.metrics import classification_report\n",
                "import os\n",
                "\n",
                "# Configuration visuelle\n",
                "plt.style.use('seaborn-v0_8-pastel')\n",
                "sns.set_theme(style=\"whitegrid\")\n",
                "COLORS = {'Train': '#EAE7DC', 'Val': '#D8C3A5', 'Test': '#8E8D8A', 'Profit': '#4E8D7C', 'Loss': '#E85A4F'}\n",
                "\n",
                "# Modification du path pour charger les fichiers séparés\n",
                "DATA_DIR = '../data/features/'"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Chargement et Préparation des Données"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_data(data_dir):\n",
                "    files = ['GBPUSD_M15_2022_features.csv', 'GBPUSD_M15_2023_features.csv', 'GBPUSD_M15_2024_features.csv']\n",
                "    dfs = []\n",
                "    for f in files:\n",
                "        path = os.path.join(data_dir, f)\n",
                "        if os.path.exists(path):\n",
                "            df_year = pd.read_csv(path, parse_dates=['timestamp'], index_col='timestamp')\n",
                "            dfs.append(df_year)\n",
                "        else:\n",
                "            print(f\"Warning: Fichier manquant {path}\")\n",
                "            \n",
                "    if not dfs:\n",
                "        raise FileNotFoundError(\"Aucun fichier de données trouvé\")\n",
                "        \n",
                "    df = pd.concat(dfs)\n",
                "    df.sort_index(inplace=True)\n",
                "    \n",
                "    # Création de la target (futur immédiat) pour le ML\n",
                "    # Shift(-1) : le return de la prochaine bougie\n",
                "    df['target_return'] = df['close_15m'].shift(-1) - df['close_15m']\n",
                "    df['target'] = (df['target_return'] > 0).astype(int)\n",
                "    \n",
                "    # Nettoyage NaN\n",
                "    df.dropna(inplace=True)\n",
                "    \n",
                "    return df\n",
                "\n",
                "df_full = load_data(DATA_DIR)\n",
                "print(f\"Données chargées (Total): {df_full.shape}\")\n",
                "\n",
                "# Split par année (automatique grâce à l'index datetime)\n",
                "train_data = df_full.loc['2022']\n",
                "val_data = df_full.loc['2023']\n",
                "test_data = df_full.loc['2024']\n",
                "\n",
                "print(f\"Train (2022): {train_data.shape}\")\n",
                "print(f\"Val (2023)  : {val_data.shape}\")\n",
                "print(f\"Test (2024) : {test_data.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Moteur de Backtest Vectorisé\n",
                "Ce moteur simule l'exécution des trades avec coûts de transaction."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Backtester:\n",
                "    def __init__(self, data, strategy_name, initial_capital=10000, transaction_cost=0.0001):\n",
                "        self.data = data.copy()\n",
                "        self.strategy_name = strategy_name\n",
                "        self.initial_capital = initial_capital\n",
                "        self.transaction_cost = transaction_cost\n",
                "        self.results = None\n",
                "\n",
                "    def run(self, signals):\n",
                "        \"\"\"\n",
                "        signals: pd.Series avec index timestamp et valeurs {1 (Buy), -1 (Sell), 0 (Cash/Hold)}\n",
                "        \"\"\"\n",
                "        # Alignement des signaux\n",
                "        self.data['signal'] = signals\n",
                "        self.data['signal'] = self.data['signal'].shift(1) # On trade à l'ouverture suivante\n",
                "        self.data['signal'].fillna(0, inplace=True)\n",
                "        \n",
                "        # Calcul des retours\n",
                "        # Si Signal 1 (Long), on gagne si Close > Open (approj). Ici on utilise return_15m (Close to Close)\n",
                "        # Simplification : Retour = Signal * Market_Return - Cost\n",
                "        \n",
                "        market_returns = self.data['return_15m']\n",
                "        \n",
                "        # Coûts : à chaque changement de position\n",
                "        trades = self.data['signal'].diff().abs()\n",
                "        costs = trades * self.transaction_cost\n",
                "        \n",
                "        strategy_returns = (self.data['signal'] * market_returns) - costs\n",
                "        \n",
                "        # Capital Curve\n",
                "        self.data['strategy_returns'] = strategy_returns\n",
                "        self.data['equity'] = (1 + strategy_returns).cumprod() * self.initial_capital\n",
                "        self.data['drawdown'] = self.data['equity'] / self.data['equity'].cummax() - 1\n",
                "        \n",
                "        return self.data['equity']\n",
                "\n",
                "    def metrics(self):\n",
                "        total_return = (self.data['equity'].iloc[-1] / self.initial_capital) - 1\n",
                "        sharpe = self.data['strategy_returns'].mean() / (self.data['strategy_returns'].std() + 1e-9) * np.sqrt(252 * 96) # M15 -> ~96 bars/day\n",
                "        max_dd = self.data['drawdown'].min()\n",
                "        \n",
                "        return {\n",
                "            'Strategy': self.strategy_name,\n",
                "            'Total Return': f\"{total_return:.2%}\",\n",
                "            'Sharpe Ratio': f\"{sharpe:.2f}\",\n",
                "            'Max Drawdown': f\"{max_dd:.2%}\",\n",
                "            'Final Equity': f\"{self.data['equity'].iloc[-1]:.2f}\"\n",
                "        }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Stratégie 1 : Règles (EMA + RSI)\n",
                "**Logique** :\n",
                "- **Tendance** : EMA 50 > EMA 200 (Long) / EMA 50 < EMA 200 (Short)\n",
                "- **Entrée** : RSI < 30 (Oversold -> Achat) / RSI > 70 (Overbought -> Vente)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def strategy_ema_rsi(df):\n",
                "    signals = pd.Series(0, index=df.index)\n",
                "    \n",
                "    # Conditions (Vectorisé)\n",
                "    # Note: Assurez-vous que les colonnes 'ema_50', 'ema_200', 'rsi_14' existent (créées dans T05)\n",
                "    # Si ema_200 n'est pas là, on utilisera ema_20 vs ema_50\n",
                "    \n",
                "    # Utilisation des colonnes existantes (d'après run_features_T05.py : ema_20, ema_50, rsi_14)\n",
                "    \n",
                "    trend_bull = df['ema_20'] > df['ema_50']\n",
                "    trend_bear = df['ema_20'] < df['ema_50']\n",
                "    \n",
                "    long_entry = trend_bull & (df['rsi_14'] < 40) # Pullback en tendance haussière\n",
                "    short_entry = trend_bear & (df['rsi_14'] > 60) # Pullback en tendance baissière\n",
                "    \n",
                "    signals[long_entry] = 1\n",
                "    signals[short_entry] = -1\n",
                "    \n",
                "    # Forward fill (Hold position until signal change or exit?)\n",
                "    # Ici on simplifie: on reste en position tant que la condition est vraie puis on sort (0).\n",
                "    # Ou mieux : on garde la dernière position (trend following)\n",
                "    signals = signals.replace(0, np.nan).fillna(method='ffill').fillna(0)\n",
                "    \n",
                "    return signals"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Stratégie 2 : Machine Learning (Random Forest)\n",
                "Entraînement sur 2022, Validation 2023 (Optimisation simulée), Test 2024."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Features pour le ML\n",
                "features_cols = ['rsi_14', 'ema_20', 'ema_50', 'atr_14', 'adx_14', 'return_15m', 'rolling_std_20']\n",
                "\n",
                "# Standardisation\n",
                "scaler = StandardScaler()\n",
                "X_train = scaler.fit_transform(train_data[features_cols])\n",
                "y_train = train_data['target']\n",
                "\n",
                "# Entraînement\n",
                "model_rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
                "model_rf.fit(X_train, y_train)\n",
                "\n",
                "# Prédiction sur Test (2024)\n",
                "X_test = scaler.transform(test_data[features_cols])\n",
                "obs_pred = model_rf.predict(X_test)\n",
                "\n",
                "# Conversion 0/1 -> -1/1 (0 -> Short, 1 -> Long)\n",
                "signals_ml = pd.Series(np.where(obs_pred == 1, 1, -1), index=test_data.index)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Exécution des Backtests sur 2024 (Test Set)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results_list = []\n",
                "\n",
                "# 1. Règles EMA+RSI\n",
                "signals_rules = strategy_ema_rsi(test_data)\n",
                "bt_rules = Backtester(test_data, \"EMA + RSI\")\n",
                "equity_rules = bt_rules.run(signals_rules)\n",
                "results_list.append(bt_rules.metrics())\n",
                "\n",
                "# 2. Machine Learning RF\n",
                "bt_ml = Backtester(test_data, \"Machine Learning (RF)\")\n",
                "equity_ml = bt_ml.run(signals_ml)\n",
                "results_list.append(bt_ml.metrics())\n",
                "\n",
                "# 3. Baseline / RL (Simulée)\n",
                "# Comme le modèle RL n'est pas entraînable ici (pas de stable-baselines3), on utilise le Buy & Hold comme baseline de référence ultime ou une stratégie aléatoire pour illustrer.\n",
                "# Note: Dans un environnement complet, on chargerait l'agent PPO ici.\n",
                "signals_bh = pd.Series(1, index=test_data.index) # Buy & Hold\n",
                "bt_bh = Backtester(test_data, \"Buy & Hold (Baseline)\")\n",
                "equity_bh = bt_bh.run(signals_bh)\n",
                "results_list.append(bt_bh.metrics())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Comparaison et Visualisation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results_df = pd.DataFrame(results_list)\n",
                "print(\"### Tableau Comparatif (Test 2024) ###\")\n",
                "display(results_df)\n",
                "\n",
                "# Plot Equity Curves\n",
                "plt.figure(figsize=(12, 6))\n",
                "plt.plot(equity_rules, label='EMA + RSI (Règles)', color='#4E8D7C', alpha=0.8)\n",
                "plt.plot(equity_ml, label='Random Forest (ML)', color='#E85A4F', alpha=0.8)\n",
                "plt.plot(equity_bh, label='Buy & Hold', color='gray', linestyle='--', alpha=0.5)\n",
                "\n",
                "plt.title(\"Comparaison des Stratégies sur 2024 (Test Set)\", fontsize=14)\n",
                "plt.ylabel(\"Capital ($)\")\n",
                "plt.xlabel(\"Temps\")\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.savefig('../artifacts/T09_comparative_equity_2024.png')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Conclusion\n",
                "\n",
                "**Analyse des Résultats** :\n",
                "- La stratégie **Rules-Based (EMA+RSI)** offre souvent un meilleur contrôle du risque (Drawdown) mais peut sous-performer en marché range.\n",
                "- Le **Machine Learning (RF)** tente de capturer des patrons non-linéaires. S'il surperforme le Buy & Hold en 2024, c'est un signe fort de robustesse.\n",
                "- Le **Buy & Hold** sert de référence de marché. Si les stratégies actives font moins bien que le Buy & Hold, elles ne valent pas le risque/coût.\n",
                "\n",
                "**Note sur le RL** : L'environnement `TradingEnv` a été défini et testé dans T08, mais l'entraînement d'un agent PPO performant nécessite des ressources de calcul et des librairies spécifiques (stable-baselines3) non disponibles ici. Pour une implémentation future, l'agent RL utiliserait les mêmes observations que le RF mais optimiserait directement la Reward (PnL ajusté du risque) plutot que la précision directionnelle."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}