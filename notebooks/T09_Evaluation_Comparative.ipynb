{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# T09 : Évaluation Comparative Robuste (ML vs Règles vs RL)\n",
                "\n",
                "## Objectif\n",
                "Ce notebook finale vise à comparer les performances de trois approches de trading sur le jeu de données de test (2024), qui n'a jamais été vu par les modèles :\n",
                "\n",
                "1.  **Approche Règles (Rule-Based)** : Stratégie classique EMA + RSI.\n",
                "2.  **Approche Machine Learning (ML)** : Random Forest (Classification de la direction).\n",
                "3.  **Approche Reinforcement Learning (RL)** : Simulation de l'environnement (Agent PPO basique/aléatoire en l'absence de librairie RL avancée).\n",
                "\n",
                "## Méthodologie\n",
                "- **Données** : GBP/USD M15 (2022-2024).\n",
                "- **Train** : 2022 | **Val** : 2023 | **Test** : 2024 (Strictement séparés).\n",
                "- **Coûts** : Spread + Commission simulés (0.0002 ou 2 pips).\n",
                "- **Métriques** : Sharpe Ratio, Max Drawdown, Profit Factor, Win Rate.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.metrics import classification_report\n",
                "import os\n",
                "\n",
                "# Configuration visuelle\n",
                "plt.style.use('seaborn-v0_8-pastel')\n",
                "sns.set_theme(style=\"whitegrid\")\n",
                "COLORS = {'Train': '#EAE7DC', 'Val': '#D8C3A5', 'Test': '#8E8D8A', 'Profit': '#4E8D7C', 'Loss': '#E85A4F'}\n",
                "\n",
                "# Modification du path pour charger les fichiers séparés\n",
                "DATA_DIR = '../data/features/'"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Chargement et Préparation des Données"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Données chargées (Total): (70768, 28)\n",
                        "Train (2022): (24696, 28)\n",
                        "Val (2023)  : (21386, 28)\n",
                        "Test (2024) : (24686, 28)\n"
                    ]
                }
            ],
            "source": [
                "def load_data(data_dir):\n",
                "    files = ['GBPUSD_M15_2022_features.csv', 'GBPUSD_M15_2023_features.csv', 'GBPUSD_M15_2024_features.csv']\n",
                "    dfs = []\n",
                "    for f in files:\n",
                "        path = os.path.join(data_dir, f)\n",
                "        if os.path.exists(path):\n",
                "            df_year = pd.read_csv(path, parse_dates=['timestamp'], index_col='timestamp')\n",
                "            dfs.append(df_year)\n",
                "        else:\n",
                "            print(f\"Warning: Fichier manquant {path}\")\n",
                "            \n",
                "    if not dfs:\n",
                "        raise FileNotFoundError(\"Aucun fichier de données trouvé\")\n",
                "        \n",
                "    df = pd.concat(dfs)\n",
                "    df.sort_index(inplace=True)\n",
                "    \n",
                "    # Création de la target (futur immédiat) pour le ML\n",
                "    # Shift(-1) : le return de la prochaine bougie\n",
                "    df['target_return'] = df['close_15m'].shift(-1) - df['close_15m']\n",
                "    df['target'] = (df['target_return'] > 0).astype(int)\n",
                "    \n",
                "    # Nettoyage NaN\n",
                "    df.dropna(inplace=True)\n",
                "    \n",
                "    return df\n",
                "\n",
                "df_full = load_data(DATA_DIR)\n",
                "print(f\"Données chargées (Total): {df_full.shape}\")\n",
                "\n",
                "# Split par année (automatique grâce à l'index datetime)\n",
                "train_data = df_full.loc['2022']\n",
                "val_data = df_full.loc['2023']\n",
                "test_data = df_full.loc['2024']\n",
                "\n",
                "print(f\"Train (2022): {train_data.shape}\")\n",
                "print(f\"Val (2023)  : {val_data.shape}\")\n",
                "print(f\"Test (2024) : {test_data.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Moteur de Backtest Vectorisé\n",
                "Ce moteur simule l'exécution des trades avec coûts de transaction."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Backtester:\n",
                "    def __init__(self, data, strategy_name, initial_capital=10000, transaction_cost=0.0001):\n",
                "        self.data = data.copy()\n",
                "        self.strategy_name = strategy_name\n",
                "        self.initial_capital = initial_capital\n",
                "        self.transaction_cost = transaction_cost\n",
                "        self.results = None\n",
                "\n",
                "    def run(self, signals):\n",
                "        \"\"\"\n",
                "        signals: pd.Series avec index timestamp et valeurs {1 (Buy), -1 (Sell), 0 (Cash/Hold)}\n",
                "        \"\"\"\n",
                "        # Alignement des signaux\n",
                "        self.data['signal'] = signals\n",
                "        self.data['signal'] = self.data['signal'].shift(1) # On trade à l'ouverture suivante\n",
                "        self.data['signal'].fillna(0, inplace=True)\n",
                "        \n",
                "        # Calcul des retours\n",
                "        # Si Signal 1 (Long), on gagne si Close > Open (approj). Ici on utilise return_15m (Close to Close)\n",
                "        # Simplification : Retour = Signal * Market_Return - Cost\n",
                "        \n",
                "        market_returns = self.data['return_15m']\n",
                "        \n",
                "        # Coûts : à chaque changement de position\n",
                "        trades = self.data['signal'].diff().abs()\n",
                "        costs = trades * self.transaction_cost\n",
                "        \n",
                "        strategy_returns = (self.data['signal'] * market_returns) - costs\n",
                "        \n",
                "        # Capital Curve\n",
                "        self.data['strategy_returns'] = strategy_returns\n",
                "        self.data['equity'] = (1 + strategy_returns).cumprod() * self.initial_capital\n",
                "        self.data['drawdown'] = self.data['equity'] / self.data['equity'].cummax() - 1\n",
                "        \n",
                "        return self.data['equity']\n",
                "\n",
                "    def metrics(self):\n",
                "        total_return = (self.data['equity'].iloc[-1] / self.initial_capital) - 1\n",
                "        sharpe = self.data['strategy_returns'].mean() / (self.data['strategy_returns'].std() + 1e-9) * np.sqrt(252 * 96) # M15 -> ~96 bars/day\n",
                "        max_dd = self.data['drawdown'].min()\n",
                "        \n",
                "        return {\n",
                "            'Strategy': self.strategy_name,\n",
                "            'Total Return': f\"{total_return:.2%}\",\n",
                "            'Sharpe Ratio': f\"{sharpe:.2f}\",\n",
                "            'Max Drawdown': f\"{max_dd:.2%}\",\n",
                "            'Final Equity': f\"{self.data['equity'].iloc[-1]:.2f}\"\n",
                "        }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Stratégie 1 : Règles (EMA + RSI)\n",
                "**Logique** :\n",
                "- **Tendance** : EMA 50 > EMA 200 (Long) / EMA 50 < EMA 200 (Short)\n",
                "- **Entrée** : RSI < 30 (Oversold -> Achat) / RSI > 70 (Overbought -> Vente)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "def strategy_ema_rsi(df):\n",
                "    signals = pd.Series(0, index=df.index)\n",
                "    \n",
                "    # Conditions (Vectorisé)\n",
                "    # Note: Assurez-vous que les colonnes 'ema_50', 'ema_200', 'rsi_14' existent (créées dans T05)\n",
                "    # Si ema_200 n'est pas là, on utilisera ema_20 vs ema_50\n",
                "    \n",
                "    # Utilisation des colonnes existantes (d'après run_features_T05.py : ema_20, ema_50, rsi_14)\n",
                "    \n",
                "    trend_bull = df['ema_20'] > df['ema_50']\n",
                "    trend_bear = df['ema_20'] < df['ema_50']\n",
                "    \n",
                "    long_entry = trend_bull & (df['rsi_14'] < 40) # Pullback en tendance haussière\n",
                "    short_entry = trend_bear & (df['rsi_14'] > 60) # Pullback en tendance baissière\n",
                "    \n",
                "    signals[long_entry] = 1\n",
                "    signals[short_entry] = -1\n",
                "    \n",
                "    # Forward fill (Hold position until signal change or exit?)\n",
                "    # Ici on simplifie: on reste en position tant que la condition est vraie puis on sort (0).\n",
                "    # Ou mieux : on garde la dernière position (trend following)\n",
                "    signals = signals.replace(0, np.nan).fillna(method='ffill').fillna(0)\n",
                "    \n",
                "    return signals"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Stratégie 2 : Machine Learning (Random Forest)\n",
                "Entraînement sur 2022, Validation 2023 (Optimisation simulée), Test 2024."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Features pour le ML\n",
                "features_cols = ['rsi_14', 'ema_20', 'ema_50', 'atr_14', 'adx_14', 'return_15m', 'rolling_std_20']\n",
                "\n",
                "# Standardisation\n",
                "scaler = StandardScaler()\n",
                "X_train = scaler.fit_transform(train_data[features_cols])\n",
                "y_train = train_data['target']\n",
                "\n",
                "# Entraînement\n",
                "model_rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
                "model_rf.fit(X_train, y_train)\n",
                "\n",
                "# Prédiction sur Test (2024)\n",
                "X_test = scaler.transform(test_data[features_cols])\n",
                "obs_pred = model_rf.predict(X_test)\n",
                "\n",
                "# Conversion 0/1 -> -1/1 (0 -> Short, 1 -> Long)\n",
                "signals_ml = pd.Series(np.where(obs_pred == 1, 1, -1), index=test_data.index)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Exécution des Backtests sur 2024 (Test Set)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\JC\\AppData\\Local\\Temp\\ipykernel_25132\\94156550.py:22: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
                        "  signals = signals.replace(0, np.nan).fillna(method='ffill').fillna(0)\n",
                        "C:\\Users\\JC\\AppData\\Local\\Temp\\ipykernel_25132\\441760473.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
                        "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
                        "\n",
                        "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
                        "\n",
                        "\n",
                        "  self.data['signal'].fillna(0, inplace=True)\n"
                    ]
                },
                {
                    "ename": "KeyError",
                    "evalue": "'return_15m'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
                        "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
                        "\u001b[31mKeyError\u001b[39m: 'return_15m'",
                        "\nThe above exception was the direct cause of the following exception:\n",
                        "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m signals_rules = strategy_ema_rsi(test_data)\n\u001b[32m      5\u001b[39m bt_rules = Backtester(test_data, \u001b[33m\"\u001b[39m\u001b[33mEMA + RSI\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m equity_rules = \u001b[43mbt_rules\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignals_rules\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m results_list.append(bt_rules.metrics())\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 2. Machine Learning RF\u001b[39;00m\n",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mBacktester.run\u001b[39m\u001b[34m(self, signals)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mself\u001b[39m.data[\u001b[33m'\u001b[39m\u001b[33msignal\u001b[39m\u001b[33m'\u001b[39m].fillna(\u001b[32m0\u001b[39m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Calcul des retours\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Si Signal 1 (Long), on gagne si Close > Open (approj). Ici on utilise return_15m (Close to Close)\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Simplification : Retour = Signal * Market_Return - Cost\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m market_returns = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mreturn_15m\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Coûts : à chaque changement de position\u001b[39;00m\n\u001b[32m     25\u001b[39m trades = \u001b[38;5;28mself\u001b[39m.data[\u001b[33m'\u001b[39m\u001b[33msignal\u001b[39m\u001b[33m'\u001b[39m].diff().abs()\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
                        "\u001b[31mKeyError\u001b[39m: 'return_15m'"
                    ]
                }
            ],
            "source": [
                "results_list = []\n",
                "\n",
                "# 1. Règles EMA+RSI\n",
                "signals_rules = strategy_ema_rsi(test_data)\n",
                "bt_rules = Backtester(test_data, \"EMA + RSI\")\n",
                "equity_rules = bt_rules.run(signals_rules)\n",
                "results_list.append(bt_rules.metrics())\n",
                "\n",
                "# 2. Machine Learning RF\n",
                "bt_ml = Backtester(test_data, \"Machine Learning (RF)\")\n",
                "equity_ml = bt_ml.run(signals_ml)\n",
                "results_list.append(bt_ml.metrics())\n",
                "\n",
                "# 3. Baseline / RL (Simulée)\n",
                "# Comme le modèle RL n'est pas entraînable ici (pas de stable-baselines3), on utilise le Buy & Hold comme baseline de référence ultime ou une stratégie aléatoire pour illustrer.\n",
                "# Note: Dans un environnement complet, on chargerait l'agent PPO ici.\n",
                "signals_bh = pd.Series(1, index=test_data.index) # Buy & Hold\n",
                "bt_bh = Backtester(test_data, \"Buy & Hold (Baseline)\")\n",
                "equity_bh = bt_bh.run(signals_bh)\n",
                "results_list.append(bt_bh.metrics())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Comparaison et Visualisation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results_df = pd.DataFrame(results_list)\n",
                "print(\"### Tableau Comparatif (Test 2024) ###\")\n",
                "display(results_df)\n",
                "\n",
                "# Plot Equity Curves\n",
                "plt.figure(figsize=(12, 6))\n",
                "plt.plot(equity_rules, label='EMA + RSI (Règles)', color='#4E8D7C', alpha=0.8)\n",
                "plt.plot(equity_ml, label='Random Forest (ML)', color='#E85A4F', alpha=0.8)\n",
                "plt.plot(equity_bh, label='Buy & Hold', color='gray', linestyle='--', alpha=0.5)\n",
                "\n",
                "plt.title(\"Comparaison des Stratégies sur 2024 (Test Set)\", fontsize=14)\n",
                "plt.ylabel(\"Capital ($)\")\n",
                "plt.xlabel(\"Temps\")\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.savefig('../artifacts/T09_comparative_equity_2024.png')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Conclusion\n",
                "\n",
                "**Analyse des Résultats** :\n",
                "- La stratégie **Rules-Based (EMA+RSI)** offre souvent un meilleur contrôle du risque (Drawdown) mais peut sous-performer en marché range.\n",
                "- Le **Machine Learning (RF)** tente de capturer des patrons non-linéaires. S'il surperforme le Buy & Hold en 2024, c'est un signe fort de robustesse.\n",
                "- Le **Buy & Hold** sert de référence de marché. Si les stratégies actives font moins bien que le Buy & Hold, elles ne valent pas le risque/coût.\n",
                "\n",
                "**Note sur le RL** : L'environnement `TradingEnv` a été défini et testé dans T08, mais l'entraînement d'un agent PPO performant nécessite des ressources de calcul et des librairies spécifiques (stable-baselines3) non disponibles ici. Pour une implémentation future, l'agent RL utiliserait les mêmes observations que le RF mais optimiserait directement la Reward (PnL ajusté du risque) plutot que la précision directionnelle."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
