{% extends "base.html" %}
{% block title %}Comparer les Mod√®les{% endblock %}

{% block content %}
<div class="page-header">
    <h2>‚öñÔ∏è Comparer les Mod√®les Publi√©s</h2>
    <p>Comparez les performances des mod√®les mis √† votre disposition et choisissez le meilleur pour pr√©dire.</p>
</div>

{% if published and published is iterable and published is not mapping and published|length > 0 %}

<!-- Mod√®les disponibles -->
<div class="grid-auto mb-3">
    {% for p in published %}
    <div class="card" style="background: var(--bg-secondary);">
        <div class="flex-between mb-2">
            <h3 style="font-size: 15px;">{{ p.model_name }}</h3>
            <span class="badge badge-green">{{ p.version }}</span>
        </div>
        <div class="btn-group mt-2">
            <a href="{{ url_for('user_predict', model_name=p.model_name, version=p.version) }}"
                class="btn btn-primary btn-sm">
                üîÆ Pr√©dire (Jour)
            </a>
            <a href="{{ url_for('user_predict', model_name=p.model_name, version=p.version, granularity='1W') }}"
                class="btn btn-outline btn-sm">
                üìÖ Semaine
            </a>
            <a href="{{ url_for('user_predict', model_name=p.model_name, version=p.version, granularity='1ME') }}"
                class="btn btn-outline btn-sm">
                üóìÔ∏è Mois
            </a>
        </div>
    </div>
    {% endfor %}
</div>

<!-- Comparaison automatique -->
{% if comparison and comparison.comparison is defined %}
<div class="card mb-3">
    <div class="card-title"><span class="icon">üìä</span> Comparaison Automatique</div>
    <div class="table-container">
        <table>
            <thead>
                <tr>
                    <th>Mod√®le</th>
                    <th>Version</th>
                    <th>Accuracy</th>
                    <th>F1 Score</th>
                    <th>AUC</th>
                    <th>Action</th>
                </tr>
            </thead>
            <tbody>
                {% for c in comparison.comparison %}
                <tr>
                    <td>{{ c.model_name }}</td>
                    <td><span class="badge badge-blue">{{ c.version }}</span></td>
                    <td
                        class="mono {% if c.accuracy > 0.52 %}text-green{% elif c.accuracy < 0.51 %}text-red{% endif %}">
                        {{ "%.2f%%"|format(c.accuracy * 100) }}
                    </td>
                    <td class="mono">{{ "%.4f"|format(c.f1_score) }}</td>
                    <td class="mono">{{ "%.4f"|format(c.roc_auc) if c.roc_auc is defined else '‚Äî' }}</td>
                    <td>
                        <a href="{{ url_for('user_predict', model_name=c.model_name, version=c.version) }}"
                            class="btn btn-primary btn-sm">Utiliser</a>
                    </td>
                </tr>
                {% endfor %}
            </tbody>
        </table>
    </div>

    <!-- Recommandation -->
    {% if comparison.comparison|length >= 2 %}
    {% set best = comparison.comparison|sort(attribute='accuracy', reverse=True)|first %}
    <div class="assessment-box positive mt-2">
        <strong>üèÜ Recommandation :</strong> Le mod√®le <strong>{{ best.model_name }} {{ best.version }}</strong>
        est le plus performant avec une accuracy de <strong>{{ "%.2f%%"|format(best.accuracy * 100) }}</strong>.
        <br>
        <a href="{{ url_for('user_predict', model_name=best.model_name, version=best.version) }}"
            class="btn btn-success btn-sm mt-1">
            Utiliser ce mod√®le ‚Üí
        </a>
    </div>
    {% endif %}
</div>
{% endif %}

{% else %}
<div class="assessment-box neutral">
    <strong>Aucun mod√®le publi√© pour le moment.</strong><br>
    Le programmeur doit d'abord entra√Æner et publier des mod√®les depuis l'interface Programmeur.
</div>
{% endif %}

<div class="card mt-3">
    <div class="card-title"><span class="icon">‚ÑπÔ∏è</span> Comment choisir un mod√®le ?</div>
    <div class="text-muted" style="font-size: 13px; line-height: 2;">
        <ul style="padding-left: 18px;">
            <li><strong>Accuracy</strong> : Le % de pr√©dictions correctes. Plus c'est haut, mieux c'est. Seuil minimum :
                <strong>52%</strong>.</li>
            <li><strong>F1 Score</strong> : √âquilibre entre Precision et Recall. Un F1 √©lev√© signifie que le mod√®le est
                √©quilibr√© dans ses erreurs.</li>
            <li><strong>ROC AUC</strong> : Capacit√© du mod√®le √† discriminer les hausses des baisses. > 0.55 = bon
                signal.</li>
            <li><strong>Granularit√©</strong> : Testez le mod√®le en jour, semaine et mois pour v√©rifier qu'il est plus
                efficace √† court terme.</li>
        </ul>
    </div>
</div>
{% endblock %}